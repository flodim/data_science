{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 1: Titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonctions utilitaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_bins(arr1, arr2):\n",
    "    '''Counts the number of bins on each dimensions for a 2d histogram'''\n",
    "    return len(set(arr1)), len(set(arr2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import des données depuis un fichier CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data = np.genfromtxt('titanic.dat', delimiter=',', skip_header=1)\n",
    "\n",
    "classes = titanic_data[:, 0]\n",
    "ages = titanic_data[:, 1]\n",
    "sexes = titanic_data[:, 2]\n",
    "survived = titanic_data[:, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nettoyage des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ages\n",
    "\n",
    "Il y a deux valeurs possibles dans la variable age : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ages_values = list(set(ages))\n",
    "ages_count_per_value = {v: sum(ages == v) for v in ages_values}\n",
    "ages_count_per_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il parait probable que la première valeur, attribuée à 2092 personnes, désigne les adultes, tandis que l'autre valeur, attribuée à 109 personnes, désigne enfants, car il y a probablement plus d'adultes que d'enfants sur le bateau.\n",
    "\n",
    "On peut binariser le tableau `ages` pour en faire un tableau `is_adult`, qui contient 1 si la personne est adulte et 0 si la personne est un enfant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_adult = (ages < 0).astype(int)\n",
    "is_adult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sexes\n",
    "\n",
    "Il y a deux valeurs possibles pour les sexes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sexes_values = list(set(sexes))\n",
    "sexes_count_per_value = {v: sum(sexes == v) for v in sexes_values}\n",
    "sexes_count_per_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il parait raisonnable de penser que sur un bateau de 1912, il y avait plus d'hommes que de femmes, soit 1731 hommes pour 470 femmes.\n",
    "\n",
    "On peut binariser le tableau `sexes` en `is_male`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_male = (sexes > 0).astype(int)\n",
    "is_male"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classes\n",
    "\n",
    "Il y a 4 valeurs possibles dans classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_values = list(set(classes))\n",
    "classes_count_per_value = {v: sum(classes== v) for v in classes_values}\n",
    "classes_count_per_value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En se renseignant un peu sur le titanic, on peut apprendre qu'il y avait 3 classes sur le bâteau, plus l'équipage. Selon wikipédia, les effectifs sont les suivants:\n",
    "\n",
    "- Première classe: 325 personnes\n",
    "- Seconde classe: 285 personnes\n",
    "- Troisième classe: 706 personnes\n",
    "- Equipage: 908 personnes\n",
    "\n",
    "Notre jeu de données ne semble pas contenir tout l'équipage, mais les autres chiffres correspondent. \n",
    "\n",
    "On peut simplifier les données en donnant des valeurs entières aux classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cleaned_class(c : int):\n",
    "    if c > 0.1:\n",
    "        return 0 # crew\n",
    "    if c < -1:\n",
    "        return 1 # first class\n",
    "    if 0 > c > -1:\n",
    "        return 2 # second class\n",
    "    if 0 < c < 0.1:\n",
    "        return 3 # third class\n",
    "\n",
    "\n",
    "classes_clean = np.array([get_cleaned_class(c) for c in classes])\n",
    "classes_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Survivants\n",
    "\n",
    "Deux valeurs sont possibles pour les survivants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survived_values = set(survived)\n",
    "survived_count_per_value = {v: sum(survived == v) for v in survived_values}\n",
    "survived_count_per_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selon [wikipédia](https://en.wikipedia.org/wiki/Passengers_of_the_RMS_Titanic#/media/File:Titanic_casualties.svg), il y a 710 survivants et 1514 victimes. On peut conclure que la valeur -1 correspond aux victimes, tandis qu la valeur 1 correspond aux survivants.\n",
    "\n",
    "On peut extraire une feature booléenne `is_survivor` de ces données:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_survivor = (survived == 1).astype(int)\n",
    "is_survivor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class vs Age vs Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig_3d = plt.figure()\n",
    "ax = Axes3D(fig_3d)\n",
    "\n",
    "\n",
    "points = list(zip(classes_clean, is_adult, is_male))\n",
    "points_values = set(points)\n",
    "points_counts = [points.count(point) for point in points_values]\n",
    "points_survivors = [sum(is_survivor[i] \n",
    "                        for i, point in enumerate(points) \n",
    "                        if point == value)\n",
    "                    for value in points_values]\n",
    "points_survivors_rates = [point_survivors / float(points_counts[i]) \n",
    "                          for i, point_survivors in enumerate(points_survivors)]\n",
    "\n",
    "x, y, z = zip(*points_values)\n",
    "\n",
    "classes_ticks = [0, 1, 2, 3]\n",
    "classes_ticklabels = ['crew', 'first class', 'second class', 'third class']\n",
    "\n",
    "is_adult_ticks = [0, 1]\n",
    "is_adult_ticklabels = ['child', 'adult']\n",
    "\n",
    "is_male_ticks = [0, 1]\n",
    "is_male_ticklabels = ['female', 'male']\n",
    "\n",
    "ax.set_xlabel('class')\n",
    "ax.set_xticks(classes_ticks)\n",
    "ax.set_xticklabels(classes_ticklabels)\n",
    "\n",
    "ax.set_ylabel('age')\n",
    "ax.set_yticks(is_adult_ticks)\n",
    "ax.set_yticklabels(is_adult_ticklabels)\n",
    "\n",
    "ax.set_zlabel('sex')\n",
    "ax.set_zticks(is_male_ticks)\n",
    "ax.set_zticklabels(is_male_ticklabels)\n",
    "\n",
    "ax.set_title('class vs age vs sex')\n",
    "s = ax.scatter(x, y, z, sizes=points_counts, c=points_survivors_rates, alpha=1)\n",
    "cbar = fig_3d.colorbar(s)\n",
    "_ = cbar.ax.set_ylabel('survival rate')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut constater dans le graphique ci-dessus que les taux de survie les plus élevés sont chez les enfants de première et seconde classe, ainsi que chez les femmes de première classe. Ceux de troisième classe sont moins chanceux.\n",
    "\n",
    "Les hommes adultes sont les plus nombreux, mais ils sont aussi ceux avec le taux de décès le plus nombreux. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classe vs Age\n",
    "\n",
    "Le graphique ci dessous affiche la nombre de personnes par classe et age. On peut constater qu'il y a plus d'adultes que d'enfants dans chaque classe, et que l'équipage ne comporte pas d'enfants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_class_age = plt.figure()\n",
    "plt.xlabel('class')\n",
    "plt.ylabel('age')\n",
    "plt.title('class vs age')\n",
    "_ = plt.hist2d(classes_clean, is_adult, norm=LogNorm(), bins=count_bins(classes_clean, ages))\n",
    "_ = plt.xticks(classes_ticks, classes_ticklabels)\n",
    "_ = plt.yticks(is_adult_ticks, is_adult_ticklabels)\n",
    "cb = plt.colorbar()\n",
    "_ = cb.ax.set_ylabel(\"number of persons\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classe vs Sexe\n",
    "\n",
    "Le graphique ci-dessous montre le nombre de personnes par classe et par sexe. On peut constater que les hommes sont plus nombreux que les femmes dans toutes les classes, et en particulier dans l'équipage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_class_sex = plt.figure()\n",
    "plt.xlabel('class')\n",
    "plt.ylabel('sex')\n",
    "plt.title('class vs sex')\n",
    "_ = plt.hist2d(classes_clean, is_male, norm=LogNorm(), bins=count_bins(classes_clean, sexes))\n",
    "_ = plt.xticks(classes_ticks, classes_ticklabels)\n",
    "_ = plt.yticks(is_male_ticks, is_male_ticklabels)\n",
    "cb = plt.colorbar()\n",
    "_ = cb.ax.set_ylabel(\"number of persons\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age vs Sexe\n",
    "\n",
    "Le graphique ci-dessous montre le nombre de personnes par age et par sexe. On peut constater que les adultes sont bien plus nombreux que les enfants. On peut aussi voir qu'il y a légérement plus de filles que de garçons chez les enfants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('age')\n",
    "plt.ylabel('sex')\n",
    "plt.title('age vs sex')\n",
    "_ = plt.hist2d(is_adult, is_male, norm=LogNorm(), bins=count_bins(ages, sexes))\n",
    "_ = plt.xticks(is_adult_ticks, is_adult_ticklabels)\n",
    "_ = plt.yticks(is_male, is_male_ticklabels)\n",
    "cb = plt.colorbar()\n",
    "_ = cb.ax.set_ylabel(\"number of persons\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recherche de K optimal\n",
    "\n",
    "Le code suivant classifie les personnes du bateau en $k$ groupes à l'aide de la méthode des _K-means_, pour $k$ variant de 1 à 50.\n",
    "\n",
    "La distance moyenne entre le barycentre de chaque groupe et ses membres est calculée pour chaque valeur de $k$, afin de pouvoir déterminer quel est le nombre de groupes optimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "data = np.array(list(zip(\n",
    "    is_adult, \n",
    "    is_male, \n",
    "    classes_clean)))\n",
    "\n",
    "K = list(range(1, 50))\n",
    "mean_dists = []\n",
    "for k in K:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "    kmeans.fit(data)\n",
    "    \n",
    "    dists = []\n",
    "    for i, label in enumerate(kmeans.labels_):\n",
    "        row = data[i]\n",
    "        cluster_center = kmeans.cluster_centers_[label]\n",
    "        dist = distance.euclidean(row, cluster_center)\n",
    "        dists.append(dist)\n",
    "    \n",
    "    mean_dist = np.mean(dists)\n",
    "    mean_dists.append(mean_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le graphique suivant montre les distances calculées ci-dessus pour chaque valeur de $k$. La distance moyenne semble se stabiliser à partir de $k=13$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.bar(K, mean_dists)\n",
    "\n",
    "_ = plt.xlabel(\"k\")\n",
    "_ = plt.ylabel(\"mean distance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour plus de précision, le graphique ci-dessous affiche les mêmes données, mais avec une échele logarithmique pour les distances.\n",
    "\n",
    "On se rend compte que la distance moyenne se stabilise vraiment à partir de $k=34$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.bar(K, mean_dists, log=True)\n",
    "_ = plt.xlabel(\"k\")\n",
    "_ = plt.ylabel(\"mean distance\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=34, random_state=0)\n",
    "kmeans.fit(data)\n",
    "\n",
    "fig_3d = plt.figure()\n",
    "ax = Axes3D(fig_3d)\n",
    "\n",
    "clusters_centers = kmeans.cluster_centers_\n",
    "labels = kmeans.labels_\n",
    "\n",
    "ax.set_xlabel('class')\n",
    "ax.set_xticks(classes_ticks)\n",
    "ax.set_xticklabels(classes_ticklabels)\n",
    "\n",
    "ax.set_ylabel('age')\n",
    "ax.set_yticks(is_adult_ticks)\n",
    "ax.set_yticklabels(is_adult_ticklabels)\n",
    "\n",
    "ax.set_zlabel('sex')\n",
    "ax.set_zticks(is_male_ticks)\n",
    "ax.set_zticklabels(is_male_ticklabels)\n",
    "\n",
    "for cluster, cluster_center in enumerate(clusters_centers, 1):\n",
    "    color = \"C\" + str(cluster % 10)\n",
    "    \n",
    "    cluster_is_adult = cluster_center[0]\n",
    "    cluster_is_male = cluster_center[1]\n",
    "    cluster_classes = cluster_center[2]\n",
    "    \n",
    "\n",
    "    ax.scatter(cluster_classes, cluster_is_adult, cluster_is_male, marker='x', color=color, sizes=[100.0])\n",
    "    row = [(classes_clean[i], is_adult[i], is_male[i])\n",
    "           for i, label in enumerate(labels)\n",
    "           if label == cluster]\n",
    "    if len(row) > 0:\n",
    "        x, y, z = zip(*row)\n",
    "        ax.scatter(x, y, z, color=color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargements des datasets breast_cancer et wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "breast_cancer = datasets.load_breast_cancer()\n",
    "wine = datasets.load_wine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation croisée à 5 segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedKFold, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from collections import defaultdict\n",
    "\n",
    "kneighbors_classifiers = {'KNeighborsClassifier(%s)' % i: \n",
    "                              KNeighborsClassifier(i) \n",
    "                          for i in range(1, 200, 10)}\n",
    "\n",
    "decisiontree_classifiers = {'DecisionTreeClassifier(min_samples_leaf=%s)' % i: \n",
    "                                DecisionTreeClassifier(min_samples_leaf=i)\n",
    "                            for i in range(1, 200, 10)}\n",
    "\n",
    "mlpc_classifiers = {\n",
    "    'MLPClassifier(hidden_layer_sizes=(%s,%s), activation=%s, early_stopping=True)'\n",
    "        % (l1, l2, activation): \n",
    "            MLPClassifier(hidden_layer_sizes=(l1,l2) if l2 > 0 else (l1,), \n",
    "                          activation=activation, \n",
    "                          early_stopping=True)\n",
    "    for l1 in {100, 400, 800}\n",
    "    for l2 in {0, 100, 400}\n",
    "    for activation in {'identity', 'logistic', 'tanh', 'relu'}\n",
    "}\n",
    "\n",
    "classifiers = dict()\n",
    "classifiers.update(kneighbors_classifiers)\n",
    "classifiers.update(decisiontree_classifiers)\n",
    "classifiers.update(mlpc_classifiers)\n",
    "\n",
    "datasets = {\n",
    "    'breast_cancer': (breast_cancer['data'], breast_cancer['target']),\n",
    "    'wine': (wine['data'], wine['target'])\n",
    "}\n",
    "\n",
    "rkf = RepeatedKFold(n_splits=5, n_repeats=10)\n",
    "\n",
    "mean_scores = defaultdict(dict)\n",
    "std_scores = defaultdict(dict)\n",
    "\n",
    "for dataset_name, dataset in datasets.items():\n",
    "    data, target = dataset\n",
    "    data = StandardScaler().fit_transform(data)\n",
    "    \n",
    "    for classifier_name, classifier in classifiers.items():\n",
    "        scores = cross_val_score(classifier, breast_cancer['data'], breast_cancer['target'], cv=rkf)\n",
    "        mean_scores[dataset_name][classifier_name] = scores.mean()\n",
    "        std_scores[dataset_name][classifier_name] = scores.std()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le graphique ci dessous montre les scores moyens avec chaque classifieur pour chaque dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (10, 100)\n",
    "\n",
    "fig, axes = plt.subplots(len(dataset), 1)\n",
    "plt.subplots_adjust(hspace=0.05)\n",
    "for i, dataset_name in enumerate(datasets.keys()):\n",
    "    scores = list(mean_scores[dataset_name].items())\n",
    "    scores.sort(key=lambda s: s[1])\n",
    "    classifier_names, values = zip(*scores)\n",
    "    stds = [std_scores[dataset_name][classifier_name] for classifier_name in classifier_names]\n",
    "    indices = list(range(len(scores)))\n",
    "    \n",
    "    ax = axes[i]\n",
    "    ax.set_title(dataset_name.replace('_', ' '))\n",
    "    ax.margins(y=0)\n",
    "    ax.barh(indices, values, tick_label=classifier_names, xerr=stds)\n",
    "    \n",
    "    for j in indices:\n",
    "        ax.text(.01, j - 0.2, '%.3f%% ± %.3f%%' % (100. * values[j], 100 * stds[j]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data from https://archive.ics.uci.edu/ml/datasets/online+news+popularity\n",
    "news_data = np.genfromtxt('onlineNewsPopularity.csv', delimiter=',', skip_header=1)\n",
    "nb_columns = np.shape(news_data)[1]\n",
    "(\n",
    "    url,  # URL of the article (non-predictive)\n",
    "    timedelta,  # Days between the article publication and the dataset acquisition (non-predictive)\n",
    "    n_tokens_title,  # Number of words in the title\n",
    "    n_tokens_content,  # Number of words in the content\n",
    "    n_unique_tokens,  # Rate of unique words in the content\n",
    "    n_non_stop_words,  # Rate of non-stop words in the content\n",
    "    n_non_stop_unique_tokens,  # Rate of unique non-stop words in the content\n",
    "    num_hrefs,  # Number of links\n",
    "    num_self_hrefs,  # Number of links to other articles published by Mashable\n",
    "    num_imgs,  # Number of images\n",
    "    num_videos,  # Number of videos\n",
    "    average_token_length,  # Average length of the words in the content\n",
    "    num_keywords,  # Number of keywords in the metadata\n",
    "    data_channel_is_lifestyle,  # Is data channel 'Lifestyle'?\n",
    "    data_channel_is_entertainment,  # Is data channel 'Entertainment'?\n",
    "    data_channel_is_bus,  # Is data channel 'Business'?\n",
    "    data_channel_is_socmed,  # Is data channel 'Social Media'?\n",
    "    data_channel_is_tech,  # Is data channel 'Tech'?\n",
    "    data_channel_is_world,  # Is data channel 'World'?\n",
    "    kw_min_min,  # Worst keyword (min. shares)\n",
    "    kw_max_min,  # Worst keyword (max. shares)\n",
    "    kw_avg_min,  # Worst keyword (avg. shares)\n",
    "    kw_min_max,  # Best keyword (min. shares)\n",
    "    kw_max_max,  # Best keyword (max. shares)\n",
    "    kw_avg_max,  # Best keyword (avg. shares)\n",
    "    kw_min_avg,  # Avg. keyword (min. shares)\n",
    "    kw_max_avg,  # Avg. keyword (max. shares)\n",
    "    kw_avg_avg,  # Avg. keyword (avg. shares)\n",
    "    self_reference_min_shares,  # Min. shares of referenced articles in Mashable\n",
    "    self_reference_max_shares,  # Max. shares of referenced articles in Mashable\n",
    "    self_reference_avg_sharess,  # Avg. shares of referenced articles in Mashable\n",
    "    weekday_is_monday,  # Was the article published on a Monday?\n",
    "    weekday_is_tuesday,  # Was the article published on a Tuesday?\n",
    "    weekday_is_wednesday,  # Was the article published on a Wednesday?\n",
    "    weekday_is_thursday,  # Was the article published on a Thursday?\n",
    "    weekday_is_friday,  # Was the article published on a Friday?\n",
    "    weekday_is_saturday,  # Was the article published on a Saturday?\n",
    "    weekday_is_sunday,  # Was the article published on a Sunday?\n",
    "    is_weekend,  # Was the article published on the weekend?\n",
    "    LDA_00,  # Closeness to LDA topic 0\n",
    "    LDA_01,  # Closeness to LDA topic 1\n",
    "    LDA_02,  # Closeness to LDA topic 2\n",
    "    LDA_03,  # Closeness to LDA topic 3\n",
    "    LDA_04,  # Closeness to LDA topic 4\n",
    "    global_subjectivity,  # Text subjectivity\n",
    "    global_sentiment_polarity,  # Text sentiment polarity\n",
    "    global_rate_positive_words,  # Rate of positive words in the content\n",
    "    global_rate_negative_words,  # Rate of negative words in the content\n",
    "    rate_positive_words,  # Rate of positive words among non-neutral tokens\n",
    "    rate_negative_words,  # Rate of negative words among non-neutral tokens\n",
    "    avg_positive_polarity,  # Avg. polarity of positive words\n",
    "    min_positive_polarity,  # Min. polarity of positive words\n",
    "    max_positive_polarity,  # Max. polarity of positive words\n",
    "    avg_negative_polarity,  # Avg. polarity of negative words\n",
    "    min_negative_polarity,  # Min. polarity of negative words\n",
    "    max_negative_polarity,  # Max. polarity of negative words\n",
    "    title_subjectivity,  # Title subjectivity\n",
    "    title_sentiment_polarity,  # Title polarity\n",
    "    abs_title_subjectivity,  # Absolute subjectivity level\n",
    "    abs_title_sentiment_polarity,  # Absolute polarity level\n",
    "    shares,  # Number of shares (target)\n",
    ") = (news_data[:, i] for i in range(nb_columns))\n",
    "\n",
    "X = list(zip(n_tokens_title, n_tokens_content, n_unique_tokens, n_non_stop_words, n_non_stop_unique_tokens, \n",
    "     num_hrefs, num_imgs, num_videos, average_token_length, num_keywords, data_channel_is_lifestyle,\n",
    "     data_channel_is_entertainment, data_channel_is_bus, data_channel_is_socmed, data_channel_is_tech,\n",
    "     data_channel_is_world, weekday_is_monday, weekday_is_tuesday, weekday_is_wednesday, weekday_is_thursday,\n",
    "     weekday_is_friday, weekday_is_saturday, weekday_is_sunday, is_weekend))\n",
    "\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "y = shares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_scores = {}\n",
    "std_scores = {}\n",
    "\n",
    "for classifier_name, classifier in classifiers.items():\n",
    "    scores = cross_val_score(classifier, breast_cancer['data'], breast_cancer['target'], cv=rkf)\n",
    "    mean_scores[classifier_name] = scores.mean()\n",
    "    std_scores[classifier_name] = scores.std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (10, 50)\n",
    "\n",
    "ax = plt.subplot()\n",
    "scores = list(mean_scores.items())\n",
    "scores.sort(key=lambda s: s[1])\n",
    "classifier_names, values = zip(*scores)\n",
    "stds = [std_scores[classifier_name] for classifier_name in classifier_names]\n",
    "indices = list(range(len(scores)))\n",
    "\n",
    "ax.set_title('news')\n",
    "ax.margins(y=0)\n",
    "ax.barh(indices, values, tick_label=classifier_names, xerr=stds)\n",
    "\n",
    "for j in indices:\n",
    "    ax.text(.01, j - 0.2, '%.3f%% ± %.3f%%' % (100. * values[j], 100 * stds[j]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
