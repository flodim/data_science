{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 1: Titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonctions utilitaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_bins(arr1, arr2):\n",
    "    '''Counts the number of bins on each dimensions for a 2d histogram'''\n",
    "    return len(set(arr1)), len(set(arr2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import des données depuis un fichier CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data = np.genfromtxt('titanic.dat', delimiter=',', skip_header=1)\n",
    "\n",
    "classes = titanic_data[:, 0]\n",
    "ages = titanic_data[:, 1]\n",
    "sexes = titanic_data[:, 2]\n",
    "survived = titanic_data[:, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nettoyage des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ages\n",
    "\n",
    "Il y a deux valeurs possibles dans la variable age : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ages_values = list(set(ages))\n",
    "ages_count_per_value = {v: sum(ages == v) for v in ages_values}\n",
    "ages_count_per_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il parait probable que la première valeur, attribuée à 2092 personnes, désigne les adultes, tandis que l'autre valeur, attribuée à 109 personnes, désigne enfants, car il y a probablement plus d'adultes que d'enfants sur le bateau.\n",
    "\n",
    "On peut binariser le tableau `ages` pour en faire un tableau `is_adult`, qui contient 1 si la personne est adulte et 0 si la personne est un enfant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_adult = (ages < 0).astype(int)\n",
    "is_adult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sexes\n",
    "\n",
    "Il y a deux valeurs possibles pour les sexes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sexes_values = list(set(sexes))\n",
    "sexes_count_per_value = {v: sum(sexes == v) for v in sexes_values}\n",
    "sexes_count_per_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il parait raisonnable de penser que sur un bateau de 1912, il y avait plus d'hommes que de femmes, soit 1731 hommes pour 470 femmes.\n",
    "\n",
    "On peut binariser le tableau `sexes` en `is_male`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_male = (sexes > 0).astype(int)\n",
    "is_male"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classes\n",
    "\n",
    "Il y a 4 valeurs possibles dans classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_values = list(set(classes))\n",
    "classes_count_per_value = {v: sum(classes== v) for v in classes_values}\n",
    "classes_count_per_value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En se renseignant un peu sur le titanic, on peut apprendre qu'il y avait 3 classes sur le bâteau, plus l'équipage. Selon wikipédia, les effectifs sont les suivants:\n",
    "\n",
    "- Première classe: 325 personnes\n",
    "- Seconde classe: 285 personnes\n",
    "- Troisième classe: 706 personnes\n",
    "- Equipage: 908 personnes\n",
    "\n",
    "Notre jeu de données ne semble pas contenir tout l'équipage, mais les autres chiffres correspondent. \n",
    "\n",
    "On peut extraire 4 nouvelles variables booléennes de la variable `class`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_first_class = (classes < -1).astype(int)\n",
    "is_second_class = ((classes < 0) & (classes > -1)).astype(int)\n",
    "is_third_class = ((classes > 0) & (classes < 0.1)).astype(int)\n",
    "is_crew = (classes > 0.1).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class vs Age vs Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig_3d = plt.figure()\n",
    "ax = Axes3D(fig_3d)\n",
    "\n",
    "ax.set_xlabel('class')\n",
    "\n",
    "ax.set_ylabel('age')\n",
    "ax.set_yticks([0, 1])\n",
    "ax.set_yticklabels([\"child\", \"adult\"])\n",
    "\n",
    "ax.set_zlabel('sex')\n",
    "\n",
    "ax.set_title('class vs age vs sex')\n",
    "_ = ax.scatter(classes, is_adult, sexes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class vs Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_class_age = plt.figure()\n",
    "plt.xlabel('class')\n",
    "plt.ylabel('age')\n",
    "plt.title('class vs age')\n",
    "_ = plt.hist2d(classes, ages, norm=LogNorm(), bins=count_bins(classes, ages))\n",
    "_ = plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class vs Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_class_sex = plt.figure(3)\n",
    "plt.xlabel('class')\n",
    "plt.ylabel('sex')\n",
    "plt.title('class vs sex')\n",
    "_ = plt.hist2d(classes, sexes, norm=LogNorm())\n",
    "_ = plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age vs Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_age_sex = plt.figure(4)\n",
    "plt.xlabel('age')\n",
    "plt.ylabel('sex')\n",
    "plt.title('age vs sex')\n",
    "_ = plt.hist2d(ages, sexes, norm=LogNorm(), bins=count_bins(ages, sexes))\n",
    "_ = plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recherche de K optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "K = list(range(1, 50))\n",
    "mean_dists = []\n",
    "for k in K:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "    kmeans.fit(titanic_data[:,:3])\n",
    "    \n",
    "    dists = []\n",
    "    for i, label in enumerate(kmeans.labels_):\n",
    "        row = titanic_data[:,:3][i]\n",
    "        cluster_center = kmeans.cluster_centers_[label]\n",
    "        dist = distance.euclidean(row, cluster_center)\n",
    "        dists.append(dist)\n",
    "    \n",
    "    mean_dist = np.mean(dists)\n",
    "    mean_dists.append(mean_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.axes().set_yscale('linear')\n",
    "_ = plt.plot(K, mean_dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.axes().set_yscale('log')\n",
    "_ = plt.plot(K, mean_dists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load breast cancer and wine datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from pprint import pprint\n",
    "\n",
    "breast_cancer = datasets.load_breast_cancer()\n",
    "wine = datasets.load_wine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "breast_cancer_kneighbors = KNeighborsClassifier().fit(breast_cancer['data'], breast_cancer['target'])\n",
    "breast_cancer_decisiontree = DecisionTreeClassifier().fit(breast_cancer['data'], breast_cancer['target'])\n",
    "breast_cancer_MLPC = MLPClassifier().fit(breast_cancer['data'], breast_cancer['target'])\n",
    "\n",
    "wine_kneighbors = KNeighborsClassifier().fit(wine['data'], wine['target'])\n",
    "wine_decisiontree = DecisionTreeClassifier().fit(wine['data'], wine['target'])\n",
    "wine_MLPC = MLPClassifier().fit(wine['data'], wine['target'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation croisée à 5 segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data from https://archive.ics.uci.edu/ml/datasets/online+news+popularity\n",
    "news_data = np.genfromtxt('onlineNewsPopularity.csv', delimiter=',', skip_header=1)\n",
    "nb_columns = np.shape(news_data)[1]\n",
    "(\n",
    "    url, # URL of the article (non-predictive)\n",
    "    timedelta, # Days between the article publication and the dataset acquisition (non-predictive)\n",
    "    n_tokens_title, # Number of words in the title\n",
    "    n_tokens_content, # Number of words in the content\n",
    "    n_unique_tokens, # Rate of unique words in the content\n",
    "    n_non_stop_words, # Rate of non-stop words in the content\n",
    "    n_non_stop_unique_tokens, # Rate of unique non-stop words in the content\n",
    "    num_hrefs, # Number of links\n",
    "    num_self_hrefs, # Number of links to other articles published by Mashable\n",
    "    num_imgs, # Number of images\n",
    "    num_videos, # Number of videos\n",
    "    average_token_length, # Average length of the words in the content\n",
    "    num_keywords, # Number of keywords in the metadata\n",
    "    data_channel_is_lifestyle, # Is data channel 'Lifestyle'?\n",
    "    data_channel_is_entertainment, # Is data channel 'Entertainment'?\n",
    "    data_channel_is_bus, # Is data channel 'Business'?\n",
    "    data_channel_is_socmed, # Is data channel 'Social Media'?\n",
    "    data_channel_is_tech, # Is data channel 'Tech'?\n",
    "    data_channel_is_world, # Is data channel 'World'?\n",
    "    kw_min_min, # Worst keyword (min. shares)\n",
    "    kw_max_min, # Worst keyword (max. shares)\n",
    "    kw_avg_min, # Worst keyword (avg. shares)\n",
    "    kw_min_max, # Best keyword (min. shares)\n",
    "    kw_max_max, # Best keyword (max. shares)\n",
    "    kw_avg_max, # Best keyword (avg. shares)\n",
    "    kw_min_avg, # Avg. keyword (min. shares)\n",
    "    kw_max_avg, # Avg. keyword (max. shares)\n",
    "    kw_avg_avg, # Avg. keyword (avg. shares)\n",
    "    self_reference_min_shares, # Min. shares of referenced articles in Mashable\n",
    "    self_reference_max_shares, # Max. shares of referenced articles in Mashable\n",
    "    self_reference_avg_sharess, # Avg. shares of referenced articles in Mashable\n",
    "    weekday_is_monday, # Was the article published on a Monday?\n",
    "    weekday_is_tuesday, # Was the article published on a Tuesday?\n",
    "    weekday_is_wednesday, # Was the article published on a Wednesday?\n",
    "    weekday_is_thursday, # Was the article published on a Thursday?\n",
    "    weekday_is_friday, # Was the article published on a Friday?\n",
    "    weekday_is_saturday, # Was the article published on a Saturday?\n",
    "    weekday_is_sunday, # Was the article published on a Sunday?\n",
    "    is_weekend, # Was the article published on the weekend?\n",
    "    LDA_00, # Closeness to LDA topic 0\n",
    "    LDA_01, # Closeness to LDA topic 1\n",
    "    LDA_02, # Closeness to LDA topic 2\n",
    "    LDA_03, # Closeness to LDA topic 3\n",
    "    LDA_04, # Closeness to LDA topic 4\n",
    "    global_subjectivity, # Text subjectivity\n",
    "    global_sentiment_polarity, # Text sentiment polarity\n",
    "    global_rate_positive_words, # Rate of positive words in the content\n",
    "    global_rate_negative_words, # Rate of negative words in the content\n",
    "    rate_positive_words, # Rate of positive words among non-neutral tokens\n",
    "    rate_negative_words, # Rate of negative words among non-neutral tokens\n",
    "    avg_positive_polarity, # Avg. polarity of positive words\n",
    "    min_positive_polarity, # Min. polarity of positive words\n",
    "    max_positive_polarity, # Max. polarity of positive words\n",
    "    avg_negative_polarity, # Avg. polarity of negative words\n",
    "    min_negative_polarity, # Min. polarity of negative words\n",
    "    max_negative_polarity, # Max. polarity of negative words\n",
    "    title_subjectivity, # Title subjectivity\n",
    "    title_sentiment_polarity, # Title polarity\n",
    "    abs_title_subjectivity, # Absolute subjectivity level\n",
    "    abs_title_sentiment_polarity, # Absolute polarity level\n",
    "    shares, # Number of shares (target)\n",
    ") = (news_data[:, i] for i in range(nb_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
